{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning How to Fit a ball-stick Model to HCP diffusion MRI data\n",
    "\n",
    "This is an adaptation of the original notebook describing the IVIM fitting approach proposed in \"Deep Learning How to Fit an Intravoxel Incoherent Motion Model to Diffusion-Weighted MRI\" by Barbieri et al., 2019. A preprint of the paper can be found at: https://arxiv.org/abs/1903.00095\n",
    "\n",
    "Note that I wrote this code quickly without much care so there's probably some bugs!\n",
    "\n",
    "Authors: Paddy Slator, Jason Lim, UCL.\n",
    "p.slator@ucl.ac.uk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2mu(xyz):\n",
    "    shape = xyz.shape[:-1]\n",
    "    mu = np.zeros(np.r_[shape, 2])\n",
    "    r = np.linalg.norm(xyz, axis=-1)\n",
    "    mu[..., 0] = np.arccos(xyz[..., 2] / r)  # theta\n",
    "    mu[..., 1] = np.arctan2(xyz[..., 1], xyz[..., 0])\n",
    "    mu[r == 0] = 0, 0\n",
    "    return mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/OneDrive\\ -\\ University\\ College\\ London/data/HCP/111312_1/T1w/Diffusion/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/Users/paddyslator/OneDrive - University College London/data/HCP/111312_1/T1w/Diffusion/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir + \"bvals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvals = np.loadtxt(datadir + \"bvals\")\n",
    "bvecs = np.loadtxt(datadir + \"bvecs\")\n",
    "\n",
    "#convert to \n",
    "bvals = bvals * 1e-03\n",
    "#\n",
    "bvecs = np.transpose(bvecs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(bvals[:,None]))\n",
    "print(np.shape(bvecs))\n",
    "\n",
    "grad = np.concatenate((bvecs,bvals[:,None]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the torch models on their own?\n",
    "\n",
    "__all__ = [\n",
    "    'ball_stick'\n",
    "]\n",
    "\n",
    "\n",
    "def ball_stick(grad,params):\n",
    "    # extract the parameters\n",
    "    f = params[:,0].unsqueeze(1)\n",
    "    Dpar = params[:, 1].unsqueeze(1)\n",
    "    Diso = params[:, 2].unsqueeze(1)\n",
    "    theta = params[:, 3].unsqueeze(1)\n",
    "    phi = params[:, 4].unsqueeze(1)    \n",
    "    \n",
    "    g = grad[:,0:2]\n",
    "    bvals = grad[:,3]\n",
    "\n",
    "    E = f * stick(grad, Dpar, theta, phi) + (1 - f) * ball(grad, Diso)\n",
    "\n",
    "    return E\n",
    "\n",
    "\n",
    "def ball(grad, Diso):\n",
    "    bvals = grad[:, 3]\n",
    "\n",
    "    E = torch.exp(-bvals * Diso)\n",
    "    return E\n",
    "\n",
    "\n",
    "def stick(grad, Dpar, theta, phi):\n",
    "    g = grad[:, 0:2]\n",
    "    bvals = grad[:, 3]\n",
    "\n",
    "    n = sphere2cart(theta, phi)\n",
    "          \n",
    "    print(np.shape(bvals * Dpar))\n",
    "    print(n)\n",
    "    \n",
    "    E = torch.exp(-bvals * Dpar * torch.mm(g, n) ** 2)\n",
    "    return E\n",
    "\n",
    "def sphere2cart(theta,phi):   \n",
    "    n = torch.zeros(3,theta.size(0))\n",
    "    \n",
    "    sintheta = torch.sin(theta)\n",
    "    print(sintheta)\n",
    "    print(theta)\n",
    "    print(n)\n",
    "    \n",
    "    n[0,:] = torch.squeeze(sintheta * torch.cos(phi))\n",
    "    n[1,:] = torch.squeeze(sintheta * torch.sin(phi))\n",
    "    n[2,:] = torch.squeeze(torch.cos(theta))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramstor = torch.tensor([[0.5, 1, 2, 0.2, 0.3],[0.2, 2, 2, 0, 2]])\n",
    "#gradtor = torch.tensor(grad)\n",
    "\n",
    "#ball_stick(gradtor, paramstor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jump straight in and define the neural network!\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, gradient_directions_no0, b_values_no0, nparams):\n",
    "        super(Net, self).__init__()\n",
    "        #add grad directions, bvals\n",
    "        self.gradient_directions_no0 = gradient_directions_no0\n",
    "        self.b_values_no0 = b_values_no0\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for i in range(3): # 3 fully connected hidden layers\n",
    "            self.fc_layers.extend([nn.Linear(len(b_values_no0), len(b_values_no0)), nn.ReLU()])\n",
    "        self.encoder = nn.Sequential(*self.fc_layers, nn.Linear(len(b_values_no0), nparams))\n",
    "\n",
    "    def forward(self, X):\n",
    "        params = torch.abs(self.encoder(X)) \n",
    "\n",
    "#         t1_ball = params[:, 0].unsqueeze(1)\n",
    "#         t1_stick = params[:, 1].unsqueeze(1)\n",
    "#         lambda_par = params[:, 2].unsqueeze(1)\n",
    "#         lambda_iso = params[:, 3].unsqueeze(1)\n",
    "#         Fp = params[:,6].unsqueeze(1)\n",
    "#         theta = params[:,4].unsqueeze(1)\n",
    "#         phi = params[:,5].unsqueeze(1)\n",
    "\n",
    "        D_par = torch.clamp(params[:, 0].unsqueeze(1), min=0.001, max=3)\n",
    "        D_iso = torch.clamp(params[:, 1].unsqueeze(1), min=0.001, max=3)\n",
    "        #Fp = torch.clamp(params[:,4].unsqueeze(1), min=0.001, max=1)\n",
    "        Fp = params[:,4].unsqueeze(1)\n",
    "        theta = params[:,2].unsqueeze(1)\n",
    "        phi = params[:,3].unsqueeze(1)\n",
    "                \n",
    "        mu_cart = torch.zeros(3,X.size()[0])\n",
    "        sintheta = torch.sin(theta)\n",
    "        mu_cart[0,:] = torch.squeeze(sintheta * torch.cos(phi))\n",
    "        mu_cart[1,:] = torch.squeeze(sintheta * torch.sin(phi))\n",
    "        mu_cart[2,:] = torch.squeeze(torch.cos(theta))\n",
    "                \n",
    "        X = Fp*torch.exp(-self.b_values_no0 * D_iso) + (1-Fp)*torch.exp(-self.b_values_no0 * D_par * torch.einsum(\"ij,jk->ki\",self.gradient_directions_no0, mu_cart) ** 2)\n",
    "        return X, D_par, D_iso, mu_cart, Fp\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "nparams = 5\n",
    "b_values_no0 = torch.FloatTensor(bvals)\n",
    "gradient_directions_no0 = torch.FloatTensor(bvecs)\n",
    "net = Net(gradient_directions_no0, b_values_no0, nparams)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "#load in some data and try fitting!\n",
    "imgnii = nib.load(datadir + \"data.nii.gz\")\n",
    "masknii = nib.load(datadir + \"nodif_brain_mask.nii.gz\")\n",
    "\n",
    "img = imgnii.get_fdata()\n",
    "mask = masknii.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image in voxel format\n",
    "nvoxtotal = np.prod(np.shape(img)[0:3])\n",
    "nvol = np.shape(img)[3]\n",
    "\n",
    "imgvox = np.reshape(img,(nvoxtotal,nvol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a smaller mask for now\n",
    "masktmp = np.zeros(np.shape(mask))\n",
    "masktmp[:,:,70] = mask[:,:,70]\n",
    "mask = masktmp\n",
    "\n",
    "#mask in voxel format\n",
    "maskvox = np.reshape(mask,(nvoxtotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgvoxtofit = imgvox[maskvox==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the data\n",
    "\n",
    "#find the volumes to normalise by - max ti, b=0\n",
    "normvol = np.where(bvals==min(bvals))\n",
    "\n",
    "imgvoxtofitnorm = imgvoxtofit/(np.tile(np.mean(imgvoxtofit[:,normvol], axis=2),(1, nvol)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create batch queues for real data\n",
    "batch_size = 128\n",
    "num_batches = len(imgvoxtofitnorm) // batch_size\n",
    "# X_train = X_train[:,1:] # exlude the b=0 value as signals are normalized\n",
    "trainloader = utils.DataLoader(torch.from_numpy(imgvoxtofitnorm.astype(np.float32)),\n",
    "                                batch_size = batch_size, \n",
    "                                shuffle = True,\n",
    "                                num_workers = 2,\n",
    "                                drop_last = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best loss\n",
    "best = 1e16\n",
    "num_bad_epochs = 0\n",
    "patience = 20\n",
    "\n",
    "# Train\n",
    "for epoch in range(1000): \n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(\"Epoch: {}; Bad epochs: {}\".format(epoch, num_bad_epochs))\n",
    "    net.train()\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, X_batch in enumerate(tqdm(trainloader), 0):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        X_pred, D_par_pred, D_iso_pred, mu_pred, Fp_pred = net(X_batch)\n",
    "        loss = criterion(X_pred, X_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "    print(\"Loss: {}\".format(running_loss))\n",
    "    # early stopping\n",
    "    if running_loss < best:\n",
    "        print(\"############### Saving good model ###############################\")\n",
    "        final_model = net.state_dict()\n",
    "        best = running_loss\n",
    "        num_bad_epochs = 0\n",
    "    else:\n",
    "        num_bad_epochs = num_bad_epochs + 1\n",
    "        if num_bad_epochs == patience:\n",
    "            print(\"Done, best loss: {}\".format(best))\n",
    "            break\n",
    "print(\"Done\")\n",
    "# Restore best model\n",
    "net.load_state_dict(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate the real data parameters with the trained network \n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    X_real_pred, D_par, D_iso, mu_cart, Fp = net(torch.from_numpy(imgvoxtofitnorm.astype(np.float32)))\n",
    "    \n",
    "X_real_pred = X_real_pred.numpy()\n",
    "D_par = D_par.numpy()\n",
    "D_iso = D_iso.numpy()\n",
    "mu_cart = mu_cart.numpy()\n",
    "Fp = Fp.numpy()\n",
    "\n",
    "mu_cart_transposed = mu_cart.transpose()\n",
    "mu_vals = cart2mu(mu_cart_transposed)\n",
    "theta = mu_vals[:,0]\n",
    "phi = mu_vals[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "D_par_vox = np.zeros(np.shape(maskvox))\n",
    "D_par_vox[maskvox==1] = np.squeeze(D_par[:])\n",
    "D_par_map = ndimage.rotate(np.reshape(D_par_vox,np.shape(mask)),90,reshape=False)\n",
    "\n",
    "D_iso_vox = np.zeros(np.shape(maskvox))\n",
    "D_iso_vox[maskvox==1] = np.squeeze(D_iso[:])\n",
    "D_iso_map = ndimage.rotate(np.reshape(D_iso_vox,np.shape(mask)),90,reshape=False)\n",
    "\n",
    "theta_vox = np.zeros(np.shape(maskvox))\n",
    "theta_vox[maskvox==1] = np.squeeze(theta[:])\n",
    "theta_map = ndimage.rotate(np.reshape(theta_vox,np.shape(mask)),90,reshape=False)\n",
    "\n",
    "phi_vox = np.zeros(np.shape(maskvox))\n",
    "phi_vox[maskvox==1] = np.squeeze(phi[:])\n",
    "phi_map = ndimage.rotate(np.reshape(phi_vox,np.shape(mask)),90,reshape=False)\n",
    "\n",
    "Fp_vox = np.zeros(np.shape(maskvox))\n",
    "Fp_vox[maskvox==1] = np.squeeze(Fp[:])\n",
    "Fp_map = ndimage.rotate(np.reshape(Fp_vox,np.shape(mask)),90,reshape=False)\n",
    "\n",
    "mu_cart_vox = np.zeros((np.shape(maskvox)[0],3))\n",
    "mu_cart_vox[maskvox==1,:] = np.transpose(mu_cart[:])\n",
    "mu_cart_map = ndimage.rotate(np.reshape(mu_cart_vox,np.append(np.shape(mask),3)),90,reshape=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 1, figsize=(5,20))\n",
    "\n",
    "zslice = 70\n",
    "\n",
    "plt0 = ax[0].imshow(D_par_map[:,:,zslice])\n",
    "plt.colorbar(plt0,ax=ax[0])\n",
    "ax[0].xaxis.set_ticklabels([]) \n",
    "ax[0].set_title('stick parallel diffusivity ($\\mu$m$^2$/ms)')\n",
    "ax[0].axis('off')\n",
    "\n",
    "plt0 = ax[1].imshow(D_iso_map[:,:,zslice])\n",
    "plt.colorbar(plt0,ax=ax[1])\n",
    "ax[1].set_title('ball isotropic diffusivity ($\\mu$m$^2$/ms)')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt0 = ax[2].imshow(theta_map[:,:,zslice])\n",
    "plt.colorbar(plt0,ax=ax[2])\n",
    "ax[2].set_title('theta')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt0 = ax[3].imshow(phi_map[:,:,zslice])\n",
    "plt.colorbar(plt0,ax=ax[3])\n",
    "ax[3].set_title('phi')\n",
    "ax[3].axis('off')\n",
    "\n",
    "plt0 = ax[4].imshow(1-Fp_map[:,:,zslice])\n",
    "plt.colorbar(plt0,ax=ax[4])\n",
    "ax[4].set_title('stick volume fraction')\n",
    "ax[4].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mu_cart_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(50,50))\n",
    "\n",
    "x,y = np.meshgrid(np.linspace(0,np.shape(mu_cart_map)[1],np.shape(mu_cart_map)[1]), np.linspace(0,np.shape(mu_cart_map)[0],np.shape(mu_cart_map)[0]))\n",
    "\n",
    "u = mu_cart_map[:,:,zslice,0]\n",
    "v = mu_cart_map[:,:,zslice,1]\n",
    "\n",
    "plt.quiver(x,y,u,v, headlength=0, headaxislength=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ca6ec867e98636ca0c4c75c3da984a3329c9a5ee8b915c41f07d90eaab86bba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
