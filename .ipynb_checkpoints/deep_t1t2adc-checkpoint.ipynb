{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning T1-T2-ADC example - adapted from deep_ivim_demo\n",
    "\n",
    "Code for unsupervised fitting of models to qMRI data.\n",
    "\n",
    "Code is adapted from Barbieri et al. https://github.com/sebbarb/deep_ivim/blob/master/deep_ivim_demo.ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define t1-t2-adc model\n",
    "def t1t2adc(b,TE,ti,D,T2,T1):\n",
    "    return abs(1 - (2*np.exp(-ti/T1)) + np.exp(-7.5/T1))*np.exp(-b*D) * np.exp(-(TE - np.min(TE))/T2)\n",
    "\n",
    "\n",
    "\n",
    "#def ball(ti, t1_, bvals, lambda_iso):\n",
    "#    return abs(1 - (2*np.exp(-ti/t1_)) + np.exp(-7.5/t1_))*np.exp(-bvals * lambda_iso) * np.exp(-(TE - np.min(TE))/T2)\n",
    "\n",
    "#def stick(ti, t1_, bvals, lambda_par, n, mu):\n",
    "#    return abs(1 - (2*np.exp(-ti/t1_)) + np.exp(-7.5/t1_))*np.exp(-bvals * lambda_par * np.dot(n, mu).transpose() ** 2) * np.exp(-(TE - np.min(TE))/T2)\n",
    "        \n",
    "#def ballstick(ti, t1_ball, t1_stick, bvals, lambda_iso, lambda_par, n, mu, Fp, s0):\n",
    "#    return s0*(Fp*(ball(ti, t1_ball, bvals, lambda_iso)) + (1-Fp)*(stick(ti, t1_stick, bvals, lambda_par, n, mu)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/yt6f867d3zq18ksrj75kk1fc0000gn/T/ipykernel_55844/472985112.py:7: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  img = imgnii.get_data()\n",
      "/var/folders/q9/yt6f867d3zq18ksrj75kk1fc0000gn/T/ipykernel_55844/472985112.py:8: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  mask = masknii.get_data()\n"
     ]
    }
   ],
   "source": [
    "maskfile='/Users/paddyslator/Library/CloudStorage/OneDrive-UniversityCollegeLondon/data/cdmri-challenge-data/cdmri11_mask.nii'\n",
    "imgfile='/Users/paddyslator/Library/CloudStorage/OneDrive-UniversityCollegeLondon/data/cdmri-challenge-data/cdmri11_r.nii'\n",
    "\n",
    "imgnii = nib.load(imgfile)\n",
    "masknii = nib.load(maskfile)\n",
    "\n",
    "img = imgnii.get_data()\n",
    "mask = masknii.get_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdim = np.shape(img)\n",
    "maskdim = np.shape(mask)\n",
    "\n",
    "imgvox = np.reshape(img, (np.prod(imgdim[0:3]),imgdim[3]))\n",
    "maskvox = np.reshape(mask, np.prod(imgdim[0:3]))\n",
    "\n",
    "#train on the voxels in the mask \n",
    "X_train = imgvox[maskvox == 1]\n",
    "\n",
    "\n",
    "#X_train nvox by nmeas - same as your .npy files \n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradechoinv = np.loadtxt('/Users/paddyslator/Library/CloudStorage/OneDrive-UniversityCollegeLondon/data/cdmri-challenge-data/gradechoinv.txt')\n",
    "\n",
    "bvecs = gradechoinv[:,0:2]\n",
    "bvals = gradechoinv[:,3]\n",
    "te = gradechoinv[:,4]\n",
    "ti = gradechoinv[:,5]\n",
    "\n",
    "#convert to sensible units\n",
    "#micrometre2/s\n",
    "bvals = bvals * 1e-3\n",
    "#seconds\n",
    "ti = ti * 1e-3\n",
    "te = te * 1e-3\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise\n",
    "\n",
    "#find the volumes to normalise by - max ti, b=0\n",
    "normvol = np.where(((bvals==min(bvals)) & (ti==max(ti)) & (te==min(te))))\n",
    "\n",
    "nvol = np.shape(X_train)[1]\n",
    "\n",
    "X_train = X_train/(np.tile(np.mean(X_train[:,normvol], axis=2),(1, nvol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the t1-t2-adc neural network\n",
    "\n",
    "model='t1t2adc'\n",
    "\n",
    "if model=='t1t2adc':\n",
    "    nparams = 3\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, b_values, TE, TI  ):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.b_values = b_values\n",
    "            self.TE = TE\n",
    "            self.TI = TI\n",
    "            self.fc_layers = nn.ModuleList()\n",
    "            for i in range(3): # 3 fully connected hidden layers\n",
    "                self.fc_layers.extend([nn.Linear(len(b_values), len(b_values)), nn.ELU()])\n",
    "            self.encoder = nn.Sequential(*self.fc_layers, nn.Linear(len(b_values), nparams))\n",
    "\n",
    "        def forward(self, X):\n",
    "            params = torch.abs(self.encoder(X)) # D, T2, T1\n",
    "            D = params[:, 0].unsqueeze(1)\n",
    "            T2 = params[:, 1].unsqueeze(1)\n",
    "            T1 = params[:,2].unsqueeze(1)\n",
    "\n",
    "    #        X = torch.exp(-self.b_values*D) * torch.exp(-(self.TE - torch.min(self.TE))/T2) \n",
    "\n",
    "            X = torch.abs(1 - (2*torch.exp(-self.TI/T1)) + torch.exp(-7.5/T1)) \\\n",
    "            * torch.exp(-self.b_values * D) \\\n",
    "            * torch.exp(-(self.TE - torch.min(self.TE))/T2)\n",
    "\n",
    "            return X, D, T2, T1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# if model=='t1t2ballstick':  \n",
    "#     nparams = 7\n",
    "#     class Net(nn.Module):\n",
    "#         def __init__(self,  b_values, TE, TI, bvecs):\n",
    "#             super(Net, self).__init__()            \n",
    "#             self.b_values = b_values\n",
    "#             self.bvecs = bvecs\n",
    "#             self.TE = TE\n",
    "#             self.TI = TI            \n",
    "            \n",
    "#             self.fc_layers = nn.ModuleList()\n",
    "#             for i in range(3): \n",
    "#                 self.fc_layers.extend([nn.Linear(len(b_values), len(b_values)), nn.ELU()])\n",
    "#             self.encoder = nn.Sequential(*self.fc_layers, nn.Linear(len(b_values), nparams))\n",
    "        \n",
    "#         def forward(self, X):\n",
    "# #             if args.dropout != 0:\n",
    "# #                 X = self.dropout(X)\n",
    "#             params = torch.abs(self.encoder(X))\n",
    "#             t1_ball_uns = params[:, 0]\n",
    "#             #t1_ball = squash(t1_ball_uns, 0.010, 5.0)\n",
    "#             t1_stick_uns = params[:, 1]\n",
    "#             #t1_stick = squash(t1_stick_uns, 0.010, 5.0)\n",
    "#             lambda_par_uns = params[:, 2]\n",
    "#             #lambda_par = squash(lambda_par_uns, 0.1, 3.0)\n",
    "#             lambda_iso_uns = params[:, 3]\n",
    "#             #lambda_iso = squash(lambda_iso_uns, 0.1, 3.0)\n",
    "#             Fp = params[:,6].unsqueeze(1)\n",
    "#             theta = params[:,4].unsqueeze(1)\n",
    "#             phi = params[:,5].unsqueeze(1)\n",
    "#             mu_cart = torch.zeros(3,X.size()[0])\n",
    "#             sintheta = torch.sin(theta)\n",
    "#             mu_cart[0,:] = torch.squeeze(sintheta * torch.cos(phi))\n",
    "#             mu_cart[1,:] = torch.squeeze(sintheta * torch.sin(phi))\n",
    "#             mu_cart[2,:] = torch.squeeze(torch.cos(theta))\n",
    "\n",
    "#             mm_prod =  torch.einsum(\"ij,jk->ki\",self.bvecs, mu_cart)\n",
    "#             X = (Fp*(torch.abs(1 - (2*torch.exp(-self.TI/t1_ball)) + torch.exp(-7.5/t1_ball))*torch.exp(-self.b_values * lambda_iso)) + (1-Fp)*(torch.abs(1 - (2*torch.exp(-self.TI/t1_stick)) + torch.exp(-7.5/t1_stick))*torch.exp(-self.b_values * lambda_par * mm_prod ** 2)))\n",
    "#             return X, t1_ball, t1_stick, lambda_par, lambda_iso, mu_cart, Fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the Network\n",
    "#b_values_no0 = torch.FloatTensor(b_values[1:])\n",
    "#TE_nomin = torch.FloatTensor(TE[1:])\n",
    "\n",
    "b_values_tor = torch.FloatTensor(bvals)\n",
    "TE_tor = torch.FloatTensor(te)\n",
    "TI_tor = torch.FloatTensor(ti)\n",
    "bvecs_tor = torch.FloatTensor(bvecs)\n",
    "\n",
    "if model=='t1t2adc':\n",
    "    net = Net(b_values_tor, TE_tor, TI_tor)\n",
    "if model=='t1t2ballstick': \n",
    "    net = Net(b_values_tor, TE_tor, TI_tor, bvecs_tor)\n",
    "\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create batch queues\n",
    "batch_size = 128\n",
    "num_batches = len(X_train) // batch_size\n",
    "\n",
    "#X_train = X_train[:,1:] # exlude the b=0 value as signals are normalized\n",
    "\n",
    "trainloader = utils.DataLoader(torch.from_numpy(X_train.astype(np.float32)),\n",
    "                                batch_size = batch_size, \n",
    "                                shuffle = True,\n",
    "                                num_workers = 2,\n",
    "                                drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Epoch: 0; Bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:13<00:00, 49.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8.28635626938194\n",
      "############### Saving good model ###############################\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 1; Bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:12<00:00, 51.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.105360396206379\n",
      "############### Saving good model ###############################\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 2; Bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:13<00:00, 50.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.01209944114089\n",
      "############### Saving good model ###############################\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 3; Bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:12<00:00, 51.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.871970220003277\n",
      "############### Saving good model ###############################\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 4; Bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:12<00:00, 51.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.033915906678885\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 5; Bad epochs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:12<00:00, 51.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.8538249474950135\n",
      "############### Saving good model ###############################\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 6; Bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:13<00:00, 49.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.786128867883235\n",
      "############### Saving good model ###############################\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 7; Bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:13<00:00, 48.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.114553299266845\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 8; Bad epochs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 657/657 [00:13<00:00, 49.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.728082481306046\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 9; Bad epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▉                                                                    | 18/657 [00:01<00:24, 26.45it/s]"
     ]
    }
   ],
   "source": [
    "# Best loss\n",
    "best = 1e16\n",
    "num_bad_epochs = 0\n",
    "patience = 10\n",
    "\n",
    "# Train\n",
    "for epoch in range(100): \n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(\"Epoch: {}; Bad epochs: {}\".format(epoch, num_bad_epochs))\n",
    "    net.train()\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, X_batch in enumerate(tqdm(trainloader), 0):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #X_pred, Dp_pred, Dt_pred, Fp_pred = net(X_batch)\n",
    "        X_pred, D_pred, T2_pred, T1_pred = net(X_batch)\n",
    "        loss = criterion(X_pred, X_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "    print(\"Loss: {}\".format(running_loss))\n",
    "    # early stopping\n",
    "    if running_loss < best:\n",
    "        print(\"############### Saving good model ###############################\")\n",
    "        final_model = net.state_dict()\n",
    "        best = running_loss\n",
    "        num_bad_epochs = 0\n",
    "    else:\n",
    "        num_bad_epochs = num_bad_epochs + 1\n",
    "        if num_bad_epochs == patience:\n",
    "            print(\"Done, best loss: {}\".format(best))\n",
    "            break\n",
    "print(\"Done\")\n",
    "# Restore best model\n",
    "net.load_state_dict(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    X_pred, D, T2, T1 = net(torch.from_numpy(X_train.astype(np.float32)))\n",
    "    \n",
    "D = D.numpy()\n",
    "T2 = T2.numpy()\n",
    "T1 = T1.numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #reshape back into image \n",
    "\n",
    "# from scipy import ndimage\n",
    "\n",
    "D_vox = np.zeros(np.shape(maskvox))\n",
    "D_vox[maskvox==1] = np.squeeze(D[:])\n",
    "D_map = np.reshape(D_vox,np.shape(mask))\n",
    "\n",
    "T2_vox = np.zeros(np.shape(maskvox))\n",
    "T2_vox[maskvox==1] = np.squeeze(T2[:])\n",
    "T2_map = np.reshape(T2_vox,np.shape(mask))\n",
    "\n",
    "T1_vox = np.zeros(np.shape(maskvox))\n",
    "T1_vox[maskvox==1] = np.squeeze(T1[:])\n",
    "T1_map = np.reshape(T1_vox,np.shape(mask))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T1_map[:,:,25])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ca6ec867e98636ca0c4c75c3da984a3329c9a5ee8b915c41f07d90eaab86bba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
